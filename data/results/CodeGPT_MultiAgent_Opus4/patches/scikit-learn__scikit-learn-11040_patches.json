{
    "sklearn/neighbors/base.py": [
        {
            "orig_text": "import warnings\nfrom abc import ABCMeta, abstractmethod\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, issparse\n\nfrom .ball_tree import BallTree\nfrom .kd_tree import KDTree\nfrom ..base import BaseEstimator\nfrom ..metrics import pairwise_distances\nfrom ..metrics.pairwise import PAIRWISE_DISTANCE_FUNCTIONS\nfrom ..utils import check_X_y, check_array, _get_n_jobs, gen_even_slices\nfrom ..utils.multiclass import check_classification_targets\nfrom ..utils.validation import check_is_fitted\nfrom ..externals import six\nfrom ..externals.joblib import Parallel, delayed\nfrom ..exceptions import NotFittedError\nfrom ..exceptions import DataConversionWarning\n",
            "new_text": "import warnings\nfrom abc import ABCMeta, abstractmethod\nimport numbers\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, issparse\n\nfrom .ball_tree import BallTree\nfrom .kd_tree import KDTree\nfrom ..base import BaseEstimator\nfrom ..metrics import pairwise_distances\nfrom ..metrics.pairwise import PAIRWISE_DISTANCE_FUNCTIONS\nfrom ..utils import check_X_y, check_array, _get_n_jobs, gen_even_slices\nfrom ..utils.multiclass import check_classification_targets\nfrom ..utils.validation import check_is_fitted\nfrom ..externals import six\nfrom ..externals.joblib import Parallel, delayed\nfrom ..exceptions import NotFittedError\nfrom ..exceptions import DataConversionWarning\n",
            "match_ratio": 1.0,
            "match_segment": "import warnings\nfrom abc import ABCMeta, abstractmethod\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix, issparse\n\nfrom .ball_tree import BallTree\nfrom .kd_tree import KDTree\nfrom ..base import BaseEstimator\nfrom ..metrics import pairwise_distances\nfrom ..metrics.pairwise import PAIRWISE_DISTANCE_FUNCTIONS\nfrom ..utils import check_X_y, check_array, _get_n_jobs, gen_even_slices\nfrom ..utils.multiclass import check_classification_targets\nfrom ..utils.validation import check_is_fitted\nfrom ..externals import six\nfrom ..externals.joblib import Parallel, delayed\nfrom ..exceptions import NotFittedError\nfrom ..exceptions import DataConversionWarning\n",
            "start_idx": 402,
            "num_matches": 1
        },
        {
            "orig_text": "class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n    \"\"\"Base class for nearest neighbors estimators.\"\"\"\n\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n",
            "new_text": "class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n    \"\"\"Base class for nearest neighbors estimators.\"\"\"\n\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        \n        # Validate n_neighbors type\n        if self.n_neighbors is not None:\n            if not isinstance(self.n_neighbors, (numbers.Integral, np.integer)):\n                raise TypeError(\"n_neighbors must be an integer, got %s instead.\"\n                                % type(self.n_neighbors))\n        \n        self._check_algorithm_metric()\n",
            "match_ratio": 1.0,
            "match_segment": "class NeighborsBase(six.with_metaclass(ABCMeta, BaseEstimator)):\n    \"\"\"Base class for nearest neighbors estimators.\"\"\"\n\n    @abstractmethod\n    def __init__(self, n_neighbors=None, radius=None,\n                 algorithm='auto', leaf_size=30, metric='minkowski',\n                 p=2, metric_params=None, n_jobs=1):\n\n        self.n_neighbors = n_neighbors\n        self.radius = radius\n        self.algorithm = algorithm\n        self.leaf_size = leaf_size\n        self.metric = metric\n        self.metric_params = metric_params\n        self.p = p\n        self.n_jobs = n_jobs\n        self._check_algorithm_metric()\n",
            "start_idx": 3983,
            "num_matches": 1
        },
        {
            "orig_text": "    def kneighbors(self, X=None, n_neighbors=None, return_distance=True):\n        \"\"\"Finds the K-neighbors of a point.\n\n        Returns indices of and distances to the neighbors of each point.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_query, n_features), \\\n                or (n_query, n_indexed) if metric == 'precomputed'\n            The query point or points.\n            If not provided, neighbors of each indexed point are returned.\n            In this case, the query point is not considered its own neighbor.\n\n        n_neighbors : int\n            Number of neighbors to get (default is the value\n            passed to the constructor).\n\n        return_distance : boolean, optional. Defaults to True.\n            If False, distances will not be returned\n\n        Returns\n        -------\n        dist : array\n            Array representing the lengths to points, only present if\n            return_distance=True\n\n        ind : array\n            Indices of the nearest points in the population matrix.\n\n        Examples\n        --------\n        In the following example, we construct a NeighborsClassifier\n        class from an array representing our data set and ask who's\n        the closest point to [1,1,1]\n\n        >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n        >>> from sklearn.neighbors import NearestNeighbors\n        >>> neigh = NearestNeighbors(n_neighbors=1)\n        >>> neigh.fit(samples) # doctest: +ELLIPSIS\n        NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n        >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n        (array([[0.5]]), array([[2]]))\n\n        As you can see, it returns [[0.5]], and [[2]], which means that the\n        element is at distance 0.5 and is the third element of samples\n        (indexes start at 0). You can also query for multiple points:\n\n        >>> X = [[0., 1., 0.], [1., 0., 1.]]\n        >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n        array([[1],\n               [2]]...)\n\n        \"\"\"\n        check_is_fitted(self, \"_fit_method\")\n\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n",
            "new_text": "    def kneighbors(self, X=None, n_neighbors=None, return_distance=True):\n        \"\"\"Finds the K-neighbors of a point.\n\n        Returns indices of and distances to the neighbors of each point.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_query, n_features), \\\n                or (n_query, n_indexed) if metric == 'precomputed'\n            The query point or points.\n            If not provided, neighbors of each indexed point are returned.\n            In this case, the query point is not considered its own neighbor.\n\n        n_neighbors : int\n            Number of neighbors to get (default is the value\n            passed to the constructor).\n\n        return_distance : boolean, optional. Defaults to True.\n            If False, distances will not be returned\n\n        Returns\n        -------\n        dist : array\n            Array representing the lengths to points, only present if\n            return_distance=True\n\n        ind : array\n            Indices of the nearest points in the population matrix.\n\n        Examples\n        --------\n        In the following example, we construct a NeighborsClassifier\n        class from an array representing our data set and ask who's\n        the closest point to [1,1,1]\n\n        >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n        >>> from sklearn.neighbors import NearestNeighbors\n        >>> neigh = NearestNeighbors(n_neighbors=1)\n        >>> neigh.fit(samples) # doctest: +ELLIPSIS\n        NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n        >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n        (array([[0.5]]), array([[2]]))\n\n        As you can see, it returns [[0.5]], and [[2]], which means that the\n        element is at distance 0.5 and is the third element of samples\n        (indexes start at 0). You can also query for multiple points:\n\n        >>> X = [[0., 1., 0.], [1., 0., 1.]]\n        >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n        array([[1],\n               [2]]...)\n\n        \"\"\"\n        check_is_fitted(self, \"_fit_method\")\n\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n        else:\n            # Validate n_neighbors type when passed as parameter\n            if not isinstance(n_neighbors, (numbers.Integral, np.integer)):\n                raise TypeError(\"n_neighbors must be an integer, got %s instead.\"\n                                % type(n_neighbors))\n",
            "match_ratio": 1.0,
            "match_segment": "    def kneighbors(self, X=None, n_neighbors=None, return_distance=True):\n        \"\"\"Finds the K-neighbors of a point.\n\n        Returns indices of and distances to the neighbors of each point.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_query, n_features), \\\n                or (n_query, n_indexed) if metric == 'precomputed'\n            The query point or points.\n            If not provided, neighbors of each indexed point are returned.\n            In this case, the query point is not considered its own neighbor.\n\n        n_neighbors : int\n            Number of neighbors to get (default is the value\n            passed to the constructor).\n\n        return_distance : boolean, optional. Defaults to True.\n            If False, distances will not be returned\n\n        Returns\n        -------\n        dist : array\n            Array representing the lengths to points, only present if\n            return_distance=True\n\n        ind : array\n            Indices of the nearest points in the population matrix.\n\n        Examples\n        --------\n        In the following example, we construct a NeighborsClassifier\n        class from an array representing our data set and ask who's\n        the closest point to [1,1,1]\n\n        >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n        >>> from sklearn.neighbors import NearestNeighbors\n        >>> neigh = NearestNeighbors(n_neighbors=1)\n        >>> neigh.fit(samples) # doctest: +ELLIPSIS\n        NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n        >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n        (array([[0.5]]), array([[2]]))\n\n        As you can see, it returns [[0.5]], and [[2]], which means that the\n        element is at distance 0.5 and is the third element of samples\n        (indexes start at 0). You can also query for multiple points:\n\n        >>> X = [[0., 1., 0.], [1., 0., 1.]]\n        >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n        array([[1],\n               [2]]...)\n\n        \"\"\"\n        check_is_fitted(self, \"_fit_method\")\n\n        if n_neighbors is None:\n            n_neighbors = self.n_neighbors\n",
            "start_idx": 10561,
            "num_matches": 1
        }
    ]
}